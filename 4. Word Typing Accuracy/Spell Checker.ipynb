{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Typing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "\n",
    "#creating object\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentance here :- Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph. Key points of the article â€“ Text into sentences tokenization\n"
     ]
    }
   ],
   "source": [
    "#enter the input here\n",
    "sentance = input(\"Enter the sentance here :- \")\n",
    "\n",
    "#spliting the sentance to get words\n",
    "words = spell.split_words(sentance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary \n",
    "listWrongWords = {}\n",
    "key = None\n",
    "value = None\n",
    "count_wrong=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the length of the word to increase our accuracy\n",
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the words spellings\n",
    "for word in words:\n",
    "    output = spell.unknown([word])\n",
    "    \n",
    "    if output:\n",
    "        output = reduce_lengthening(word)\n",
    "        value = spell.correction(word)\n",
    "        listWrongWords[word] = value\n",
    "        count_wrong=count_wrong+1\n",
    "    else:\n",
    "        listWrongWords[word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entered word\tCorrect word\n",
      "tokenization\ttokenization\n",
      "is\tis\n",
      "the\tthe\n",
      "process\tprocess\n",
      "of\tof\n",
      "tokenizing\ttokenizing\n",
      "or\tor\n",
      "splitting\tsplitting\n",
      "a\ta\n",
      "string\tstring\n",
      "text\ttext\n",
      "into\tinto\n",
      "list\tlist\n",
      "tokens\ttokens\n",
      "one\tone\n",
      "can\tcan\n",
      "think\tthink\n",
      "token\ttoken\n",
      "as\tas\n",
      "parts\tparts\n",
      "like\tlike\n",
      "word\tword\n",
      "in\tin\n",
      "sentence\tsentence\n",
      "and\tand\n",
      "paragraph\tparagraph\n",
      "key\tkey\n",
      "points\tpoints\n",
      "article\tarticle\n",
      "sentences\tsentences\n"
     ]
    }
   ],
   "source": [
    "#printing the output\n",
    "print(\"\\nEntered word\\tCorrect word\")\n",
    "\n",
    "#printing the output\n",
    "for key,value in listWrongWords.items():\n",
    "    print(\"{}\\t{}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of typing is :-  94.0\n"
     ]
    }
   ],
   "source": [
    "#checking the accuracy\n",
    "count_words = len(words)\n",
    "\n",
    "accuracy = 100 - (count_wrong / count_words * 100)\n",
    "print(\"\\nAccuracy of typing is :- \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
